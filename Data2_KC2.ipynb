{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "file_exists = os.path.exists(\"inst_full.csv\")\n",
    "\n",
    "print(file_exists)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE CELL BEOW CHECKS TO SEE IF YOU ALREADY HAVE THE DATA AND IF NOT SENDS GET REQUESTS TO THE API\n",
    "\n",
    "NOTE - THIS DOES NOT CHECK TO ENSURE THE FILE IS CURRENT OR FREE OF ERRORS.  IF YOU WOULD LIKE TO UPDATE YOUR FILE OR YOU ARE CONCERNED THAT YOUR FILE HAS ERRORS, SIMPLY DELETE YOUR FILE AND A NEW, UPDATED FILE WILL BE CREATED."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. KNOWLEDGE CHECK 2 - See the last 20 lines in the cell below (most of the code in the ELSE statement).  This cleans the data by checking for columns with mixed data types and converting the entire column to strings.  It converts the data type, but also displays an error to identify the affected columns.  This is a solution I found on stackoverflow that I wanted to implement in my code.\n",
    "\n",
    "Knowledge Check 2 - Also see cells 4, 5, 7, 9, and 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE ALREADY EXISTS\n",
      "Warnings raised: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjlaw\\AppData\\Local\\Temp\\ipykernel_28264\\3671726210.py:82: DtypeWarning: Columns (108,109,110,152) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('inst_full.csv')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas\n",
    "\n",
    "\n",
    "if file_exists == False:\n",
    "    print(\"FILE DOES NOT EXIST\")\n",
    "\n",
    "    response_API = requests.get('https://banks.data.fdic.gov/api/institutions?limit=10000&offset=0')\n",
    "    #print(response_API.status_code)\n",
    "\n",
    "    response_API2 = requests.get('https://banks.data.fdic.gov/api/institutions?limit=10000&offset=10000')\n",
    "    #print(response_API2.status_code)\n",
    "\n",
    "    response_API3 = requests.get('https://banks.data.fdic.gov/api/institutions?limit=10000&offset=20000')\n",
    "    #print(response_API3.status_code)\n",
    "\n",
    "    print(\"Get request sucessful from API\")\n",
    "\n",
    "\n",
    "    data = response_API.json()\n",
    "    #print(type(data))\n",
    "\n",
    "    data2 = response_API2.json()\n",
    "    #print(type(data2))\n",
    "\n",
    "    data3 = response_API3.json()\n",
    "    #print(type(data3))\n",
    "\n",
    "\n",
    "\n",
    "    institution_df = json_normalize(data['data'])\n",
    "    #print(institution_df.head())\n",
    "    #institution_df.to_csv('inst.csv')\n",
    "\n",
    "    institution_df2 = json_normalize(data2['data'])\n",
    "    #print(institution_df2.head())\n",
    "    #institution_df2.to_csv('inst2.csv')\n",
    "\n",
    "    institution_df3 = json_normalize(data3['data'])\n",
    "    #print(institution_df3.head())\n",
    "    #institution_df3.to_csv('inst3.csv')\n",
    "    \n",
    "    print(\"Data from API converted to json\")\n",
    "\n",
    "\n",
    "    institution_df = institution_df.reindex(sorted(institution_df.columns), axis=1)\n",
    "    institution_df2 = institution_df2.reindex(sorted(institution_df2.columns), axis=1)\n",
    "    institution_df3 = institution_df3.reindex(sorted(institution_df3.columns), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    full_data = [institution_df, institution_df2, institution_df3]\n",
    "    df = pd.concat(full_data)\n",
    "    df.columns = df.columns.str.lstrip(\"data.\")\n",
    "    df.to_csv('inst_full.csv')\n",
    "    \n",
    "    print(\"New file created, shape should be (27816, 168)\")\n",
    "    print(df.shape)\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(\"FILE ALREADY EXISTS\")\n",
    "\n",
    "    myfile = 'inst_full.csv'\n",
    "    target_type = str  # The desired output type\n",
    "\n",
    "    with warnings.catch_warnings(record=True) as ws:\n",
    "        warnings.simplefilter(\"always\")\n",
    "\n",
    "        mydata = pandas.read_csv(myfile, sep=\"|\", header=None)\n",
    "        print(\"Warnings raised:\", ws)\n",
    "        # We have an error on specific columns, try and load them as string\n",
    "        for w in ws:\n",
    "            s = str(w.message)\n",
    "            print(\"Warning message:\", s)\n",
    "            match = re.search(r\"Columns \\(([0-9,]+)\\) have mixed types\\.\", s)\n",
    "            if match:\n",
    "                columns = match.group(1).split(',') # Get columns as a list\n",
    "                columns = [int(c) for c in columns]\n",
    "                print(\"Applying %s dtype to columns:\" % target_type, columns)\n",
    "                mydata.iloc[:,columns] = mydata.iloc[:,columns].astype(target_type)\n",
    "\n",
    "    df = pd.read_csv('inst_full.csv')\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Knowledge Check 2 - Removing unecessary rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.iloc[:, 165:168],axis = 1)\n",
    "df = df.drop(df.iloc[:, 141:156],axis = 1)\n",
    "df = df.drop(df.iloc[:, 106:110],axis = 1)\n",
    "df = df.drop(df.iloc[:, 22:31],axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Knowledge Check 2 - Reformating the column names so they are all lower case and spaces are replaced with an underscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.columns)\n",
    "df.columns= df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3547\n",
      "   Record ID Docket Number     IID  \\\n",
      "0          1            29    29.0   \n",
      "1          2          8327  8327.0   \n",
      "2          3          3916  3916.0   \n",
      "3          4           NaN     NaN   \n",
      "4          5           NaN     NaN   \n",
      "\n",
      "                                   Unnamed: 3 DOCASSOCIATION Unnamed: 5  \\\n",
      "0  http://www.occ.gov/static/ots/enforcement/          93296       .pdf   \n",
      "1  http://www.occ.gov/static/ots/enforcement/          93221       .pdf   \n",
      "2  http://www.occ.gov/static/ots/enforcement/          93233       .pdf   \n",
      "3  http://www.occ.gov/static/ots/enforcement/          93799       .pdf   \n",
      "4  http://www.occ.gov/static/ots/enforcement/          94981       .pdf   \n",
      "\n",
      "                                          Unnamed: 6  \\\n",
      "0  http://www.occ.gov/static/ots/enforcement/9329...   \n",
      "1  http://www.occ.gov/static/ots/enforcement/9322...   \n",
      "2  http://www.occ.gov/static/ots/enforcement/9323...   \n",
      "3  http://www.occ.gov/static/ots/enforcement/9379...   \n",
      "4  http://www.occ.gov/static/ots/enforcement/9498...   \n",
      "\n",
      "                                          Unnamed: 7  \\\n",
      "0  http://www.occ.gov/static/ots/enforcement/9329...   \n",
      "1  http://www.occ.gov/static/ots/enforcement/9322...   \n",
      "2  http://www.occ.gov/static/ots/enforcement/9323...   \n",
      "3  http://www.occ.gov/static/ots/enforcement/9379...   \n",
      "4  http://www.occ.gov/static/ots/enforcement/9498...   \n",
      "\n",
      "                          Link to Enforcement Action Order Number  ...  \\\n",
      "0  http://www.occ.gov/static/ots/enforcement/9329...    DAL 96-18  ...   \n",
      "1  http://www.occ.gov/static/ots/enforcement/9322...    ATL 97-06  ...   \n",
      "2  http://www.occ.gov/static/ots/enforcement/9323...    MWR 97-17  ...   \n",
      "3  http://www.occ.gov/static/ots/enforcement/9379...    OTS 93-45  ...   \n",
      "4  http://www.occ.gov/static/ots/enforcement/9498...     NY 90-17  ...   \n",
      "\n",
      "    First Name Last Name               City State OTS Region Issue Date  \\\n",
      "0   Martha Sue     Abney          Texarkana    AR    Western   8/7/1996   \n",
      "1    Christina    Acosta  North Miami Beach    FL  Southeast  8/28/1997   \n",
      "2   Melissa J.     Acuna            Roswell    NM    Western  11/6/1997   \n",
      "3        Mario    Albini          Waterbury    CT  Northeast   6/3/1993   \n",
      "4  Jose Manuel  Alcorcer           Santurce    PR  Southeast   7/3/1990   \n",
      "\n",
      "  Type Code               Type Description Type of Order Notes  \n",
      "0      15.0  Orders of Removal/Prohibition   Prohibition   NaN  \n",
      "1      15.0  Orders of Removal/Prohibition   Prohibition   NaN  \n",
      "2      15.0  Orders of Removal/Prohibition   Prohibition   NaN  \n",
      "3      15.0  Orders of Removal/Prohibition   Prohibition   NaN  \n",
      "4      15.0  Orders of Removal/Prohibition   Prohibition   NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#To add banks with FDIC violations\n",
    "\n",
    "absolute_path = os.path.abspath('')\n",
    "relative_path = \"ots-enforcement-order-listing.csv\"\n",
    "full_path = os.path.join(absolute_path, relative_path)\n",
    "enforcment_df = pd.read_csv(full_path)\n",
    "print(len(enforcment_df))\n",
    "print(enforcment_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge Check 2 - making all column names lower case and replacing spaces with underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Record ID', 'Docket Number', 'IID', 'Unnamed: 3', 'DOCASSOCIATION',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Link to Enforcement Action',\n",
      "       'Order Number', 'Institution Name', 'First Name', 'Last Name', 'City',\n",
      "       'State', 'OTS Region', 'Issue Date', 'Type Code', 'Type Description',\n",
      "       'Type of Order', 'Notes'],\n",
      "      dtype='object')\n",
      "Index(['record_id', 'docket_number', 'iid', 'unnamed:_3', 'docassociation',\n",
      "       'unnamed:_5', 'unnamed:_6', 'unnamed:_7', 'link_to_enforcement_action',\n",
      "       'order_number', 'institution_name', 'first_name', 'last_name', 'city',\n",
      "       'state', 'ots_region', 'issue_date', 'type_code', 'type_description',\n",
      "       'type_of_order', 'notes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print(enforcment_df.columns)\n",
    "enforcment_df.columns= enforcment_df.columns.str.lower()\n",
    "enforcment_df.columns = enforcment_df.columns.str.replace(' ', '_')\n",
    "#print(enforcment_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for d in enforcment_df['docket_number'].astype(str):\n",
    "#    if enforcment_df['docket_number'].str.startswith('H'):\n",
    "#        enforcment_df['docket_number'].str.replace(' ', '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Knowledge Check 2 - Removes improperly formatted docket numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enforcment_df['docket_number'] = np.where(enforcment_df['docket_number'].str.startswith('H'), '', enforcment_df['docket_number'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Knowldge Check 2 - Removes rows with no docket number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2029\n",
      "      record_id docket_number      iid  \\\n",
      "1391       1463           100    100.0   \n",
      "2907       3018           100    100.0   \n",
      "1268       1337           100    100.0   \n",
      "538         551         10100  10100.0   \n",
      "2382       2478          1016   1016.0   \n",
      "\n",
      "                                      unnamed:_3 docassociation unnamed:_5  \\\n",
      "1391  http://www.occ.gov/static/ots/enforcement/          94571       .pdf   \n",
      "2907  http://www.occ.gov/static/ots/enforcement/          97102       .pdf   \n",
      "1268  http://www.occ.gov/static/ots/enforcement/          93646       .pdf   \n",
      "538   http://www.occ.gov/static/ots/enforcement/          93574       .pdf   \n",
      "2382  http://www.occ.gov/static/ots/enforcement/          96124       .pdf   \n",
      "\n",
      "                                             unnamed:_6  \\\n",
      "1391  http://www.occ.gov/static/ots/enforcement/9457...   \n",
      "2907  http://www.occ.gov/static/ots/enforcement/9710...   \n",
      "1268  http://www.occ.gov/static/ots/enforcement/9364...   \n",
      "538   http://www.occ.gov/static/ots/enforcement/9357...   \n",
      "2382  http://www.occ.gov/static/ots/enforcement/9612...   \n",
      "\n",
      "                                             unnamed:_7  \\\n",
      "1391  http://www.occ.gov/static/ots/enforcement/9457...   \n",
      "2907  http://www.occ.gov/static/ots/enforcement/9710...   \n",
      "1268  http://www.occ.gov/static/ots/enforcement/9364...   \n",
      "538   http://www.occ.gov/static/ots/enforcement/9357...   \n",
      "2382  http://www.occ.gov/static/ots/enforcement/9612...   \n",
      "\n",
      "                             link_to_enforcement_action order_number  ...  \\\n",
      "1391  http://www.occ.gov/static/ots/enforcement/9457...    MWR 06-02  ...   \n",
      "2907  http://www.occ.gov/static/ots/enforcement/9710...     WN-09-06  ...   \n",
      "1268  http://www.occ.gov/static/ots/enforcement/9364...    MWR 04-15  ...   \n",
      "538   http://www.occ.gov/static/ots/enforcement/9357...    CHI 94-34  ...   \n",
      "2382  http://www.occ.gov/static/ots/enforcement/9612...           SA  ...   \n",
      "\n",
      "          first_name last_name        city state ots_region  issue_date  \\\n",
      "1391       Kristi B.   Robbins       Paris    TX    Western   2/22/2006   \n",
      "2907       Angela D.     Hobbs       Paris    TX    Western   4/17/2009   \n",
      "1268  Christopher G.   Mallory       Paris    TX    Western   9/21/2004   \n",
      "538         Cloyd A.  Singhass   Cleveland    OH    Central  12/14/1994   \n",
      "2382             NaN       NaN  Cincinnati    OH    Central    2/4/1999   \n",
      "\n",
      "     type_code               type_description type_of_order notes  \n",
      "1391      15.0  Orders of Removal/Prohibition           NaN   NaN  \n",
      "2907      15.0  Orders of Removal/Prohibition           NaN   NaN  \n",
      "1268      15.0  Orders of Removal/Prohibition           NaN   NaN  \n",
      "538       15.0  Orders of Removal/Prohibition   Prohibition   NaN  \n",
      "2382      13.0          Supervisory Agreement           NaN   NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "#create a new df so the old df is unaltered\n",
    "\n",
    "#sorts the new df by docket number\n",
    "enf_df1 = enforcment_df.sort_values('docket_number')\n",
    "\n",
    "#converts emtpy strings to NaN and then drops rows that do not have a Docket Number\n",
    "enf_df1['docket_number'].replace('', np.nan, inplace=True)\n",
    "enf_df1.dropna(subset=['docket_number'], inplace=True)\n",
    "\n",
    "#Gives the size and first columns of the new_enf_df\n",
    "print(len(enf_df1.sort_values('docket_number')))\n",
    "print(enf_df1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops duplicates and adds 2 new colums to the new_enf_df\n",
    "\n",
    "short_enf_df = enf_df1.drop_duplicates(subset=['docket_number'], keep='last')\n",
    "#short_enf_df = short_enf_df.reindex(columns = new_enf_df.columns.tolist() + ['Number_of_Violations','Unique_Violations'])\n",
    "\n",
    "#Gives the size and first columns of the short_enf_df\n",
    "#print(len(short_enf_df))\n",
    "#print(short_enf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_count_df = enf_df1.pivot_table(index = ['docket_number'], aggfunc ='size')\n",
    "vc_df = violation_count_df.reset_index()\n",
    "vc_df.columns = ['docket_number', 'total_violations']\n",
    "#print(vc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_violation_count_df = enf_df1.pivot_table(index = ['docket_number', \"issue_date\"], aggfunc ='size')\n",
    "uvc_df = unique_violation_count_df.reset_index()\n",
    "uvc_df.columns = ['docket_number', 'issue_date', 'violations']\n",
    "#print(uvc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_uvc_df = uvc_df.pivot_table(index = ['docket_number'], aggfunc ='size')\n",
    "fvc_df = violation_count_df.reset_index()\n",
    "fvc_df.columns = ['docket_number', 'unique_violations']\n",
    "#print(fvc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_stats_df = vc_df.merge(fvc_df)\n",
    "#print(violation_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_enf_df = short_enf_df.merge(violation_stats_df)\n",
    "#print(final_enf_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        unnamed:_0  active              address address2     asset bkclass  \\\n",
      "0               0       0  8 Washington Street      NaN       NaN      SM   \n",
      "1               1       0    201 N.E. A Street      NaN  712714.0      SM   \n",
      "2               2       0  1701 Warwood Avenue      NaN  338215.0       N   \n",
      "3               3       0   1 East Main Street      NaN  126549.0      SM   \n",
      "4               4       1        86 E Water St      NaN  144049.0      NM   \n",
      "...           ...     ...                  ...      ...       ...     ...   \n",
      "27811        7811       0     3425 Main Street      NaN       NaN      NM   \n",
      "27812        7812       0          Main Street      NaN   62371.0      NM   \n",
      "27813        7813       0       333 Penco Road      NaN  178789.0      NM   \n",
      "27814        7814       1  105 E Washington St      NaN  454657.0      NM   \n",
      "27815        7815       1          2 W Main St      NaN  200966.0      NM   \n",
      "\n",
      "       callform   cb                                          cbsa  \\\n",
      "0           NaN  NaN                   Portland-South Portland, ME   \n",
      "1          41.0  0.0            Fayetteville-Springdale-Rogers, AR   \n",
      "2          41.0  1.0                               Wheeling, WV-OH   \n",
      "3          33.0  0.0                                           NaN   \n",
      "4          51.0  1.0                                           NaN   \n",
      "...         ...  ...                                           ...   \n",
      "27811       NaN  NaN                   Weirton-Steubenville, WV-OH   \n",
      "27812      34.0  1.0                                Charleston, WV   \n",
      "27813      33.0  0.0                   Weirton-Steubenville, WV-OH   \n",
      "27814      51.0  1.0  Washington-Arlington-Alexandria, DC-VA-MD-WV   \n",
      "27815      51.0  1.0                                           NaN   \n",
      "\n",
      "                                           cbsa_div  ...  city_y  state  \\\n",
      "0                                               NaN  ...     NaN    NaN   \n",
      "1                                               NaN  ...     NaN    NaN   \n",
      "2                                               NaN  ...     NaN    NaN   \n",
      "3                                               NaN  ...     NaN    NaN   \n",
      "4                                               NaN  ...     NaN    NaN   \n",
      "...                                             ...  ...     ...    ...   \n",
      "27811                                           NaN  ...     NaN    NaN   \n",
      "27812                                           NaN  ...     NaN    NaN   \n",
      "27813                                           NaN  ...     NaN    NaN   \n",
      "27814  Washington-Arlington-Alexandria, DC-VA-MD-WV  ...     NaN    NaN   \n",
      "27815                                           NaN  ...     NaN    NaN   \n",
      "\n",
      "       ots_region  issue_date type_code  type_description  type_of_order  \\\n",
      "0             NaN         NaN       NaN               NaN            NaN   \n",
      "1             NaN         NaN       NaN               NaN            NaN   \n",
      "2             NaN         NaN       NaN               NaN            NaN   \n",
      "3             NaN         NaN       NaN               NaN            NaN   \n",
      "4             NaN         NaN       NaN               NaN            NaN   \n",
      "...           ...         ...       ...               ...            ...   \n",
      "27811         NaN         NaN       NaN               NaN            NaN   \n",
      "27812         NaN         NaN       NaN               NaN            NaN   \n",
      "27813         NaN         NaN       NaN               NaN            NaN   \n",
      "27814         NaN         NaN       NaN               NaN            NaN   \n",
      "27815         NaN         NaN       NaN               NaN            NaN   \n",
      "\n",
      "       notes total_violations unique_violations  \n",
      "0        NaN              NaN               NaN  \n",
      "1        NaN              NaN               NaN  \n",
      "2        NaN              NaN               NaN  \n",
      "3        NaN              NaN               NaN  \n",
      "4        NaN              NaN               NaN  \n",
      "...      ...              ...               ...  \n",
      "27811    NaN              NaN               NaN  \n",
      "27812    NaN              NaN               NaN  \n",
      "27813    NaN              NaN               NaN  \n",
      "27814    NaN              NaN               NaN  \n",
      "27815    NaN              NaN               NaN  \n",
      "\n",
      "[27816 rows x 161 columns]>\n"
     ]
    }
   ],
   "source": [
    "df['docket'] = df['docket'].astype(str)\n",
    "final_df = df.merge(final_enf_df, how='left', left_on='docket', right_on='docket_number')\n",
    "print(final_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0589475581bafe2bbc330412b8cf2cd44fed02eacf7679fc9db622cc240f316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
